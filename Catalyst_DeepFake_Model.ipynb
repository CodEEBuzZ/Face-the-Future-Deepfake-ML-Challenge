{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhgPROKWeB2J"
   },
   "source": [
    "CELL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fyBzSDvZdrtK",
    "outputId": "391d6812-0e9a-4c73-dffc-ed55cbc849b4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYKddoodeGZG"
   },
   "source": [
    "CELL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvCxIkBdeBZ0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpFOykTceIBi"
   },
   "source": [
    "CELL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUtvh-78eBXD",
    "outputId": "ee4ca985-f98c-4a1f-846b-4e2cdcfc77fe"
   },
   "outputs": [],
   "source": [
    "base_path = \"/content/drive/My Drive/DATASET/\"\n",
    "\n",
    "# Define paths based on the base path\n",
    "real_images_path = os.path.join(base_path, \"real_cifake_images\")\n",
    "fake_images_path = os.path.join(base_path, \"fake_cifake_images\")\n",
    "real_json_path = os.path.join(base_path, \"real_cifake_preds.json\")\n",
    "fake_json_path = os.path.join(base_path, \"fake_cifake_preds.json\")\n",
    "\n",
    "output_csv_path = \"/content/training_master.csv\"\n",
    "\n",
    "print(f\"Real images folder: {real_images_path}\")\n",
    "print(f\"Fake images folder: {fake_images_path}\")\n",
    "print(f\"Real JSON file: {real_json_path}\")\n",
    "print(f\"Fake JSON file: {fake_json_path}\")\n",
    "print(f\"Output CSV will be saved to: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jokvTrdceKCZ"
   },
   "source": [
    "CELL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkU8B9JfeBUm",
    "outputId": "9985fb12-81a2-4fa7-d92a-ca0bbffaa331"
   },
   "outputs": [],
   "source": [
    "# This list will hold all our data before we make the CSV\n",
    "master_list = []\n",
    "\n",
    "# --- 1. Process the REAL images ---\n",
    "print(\"Processing real_cifake_preds.json...\")\n",
    "with open(real_json_path, 'r') as f:\n",
    "    real_data = json.load(f)\n",
    "\n",
    "for item in real_data:\n",
    "    index = item['index']\n",
    "    label = item['prediction']  # This will be 'real' or 'fake'\n",
    "\n",
    "    # The filenames are 1.png, 2.png, etc.\n",
    "    image_name = f\"{index}.png\"\n",
    "    # -----------\n",
    "\n",
    "    # Create the full path to the image\n",
    "    image_path = os.path.join(real_images_path, image_name)\n",
    "\n",
    "    # Add the data to our master list\n",
    "    master_list.append({\n",
    "        'image_path': image_path,\n",
    "        'label': label\n",
    "    })\n",
    "\n",
    "print(f\"Processed {len(real_data)} real image records.\")\n",
    "\n",
    "# --- 2. Process the FAKE images ---\n",
    "print(\"\\nProcessing fake_cifake_preds.json...\")\n",
    "with open(fake_json_path, 'r') as f:\n",
    "    fake_data = json.load(f)\n",
    "\n",
    "for item in fake_data:\n",
    "    index = item['index']\n",
    "    label = item['prediction']  # This will always be 'fake'\n",
    "\n",
    "    # --- FIX ---\n",
    "    image_name = f\"{index}.png\"\n",
    "    # -----------\n",
    "\n",
    "    image_path = os.path.join(fake_images_path, image_name)\n",
    "\n",
    "    # Add the data to our master list\n",
    "    master_list.append({\n",
    "        'image_path': image_path,\n",
    "        'label': label\n",
    "    })\n",
    "\n",
    "print(f\"Processed {len(fake_data)} fake image records.\")\n",
    "\n",
    "# --- 3. Convert to Pandas DataFrame and Save ---\n",
    "print(\"\\nConverting to DataFrame...\")\n",
    "df = pd.DataFrame(master_list)\n",
    "\n",
    "# Save the DataFrame to our CSV file (using the local path)\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"\\nSUCCESS! Master CSV created with {len(df)} total records.\")\n",
    "print(f\"File saved to: {output_csv_path}\")\n",
    "\n",
    "# --- 4. Display a sample of the data ---\n",
    "print(\"\\nHere's a sample of your master dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coOuT3m5eMHP"
   },
   "source": [
    "CELL 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBNiPdszeBR7",
    "outputId": "7360f18a-ce3b-4dbc-e8bb-2d64a1194d1c"
   },
   "outputs": [],
   "source": [
    "# Install our required libraries\n",
    "!pip install timm scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96-r00TaeNud"
   },
   "source": [
    "CELL 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mltFhQCUeBPU",
    "outputId": "fc05c658-0bde-4e88-e6a9-7029c8e7de9f"
   },
   "outputs": [],
   "source": [
    "# [THIS IS THE CORRECTED CELL 5.5]\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Starting to copy dataset from Drive to local Colab disk...\")\n",
    "print(\"This might take a minute or two, but we only do it once.\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Define source paths on Google Drive\n",
    "drive_real_path = \"/content/drive/My Drive/DATASET/real_cifake_images\"\n",
    "drive_fake_path = \"/content/drive/My Drive/DATASET/fake_cifake_images\"\n",
    "\n",
    "# Define destination paths on the fast local Colab disk\n",
    "local_real_path = \"/content/local_dataset/real_cifake_images\"\n",
    "local_fake_path = \"/content/local_dataset/fake_cifake_images\"\n",
    "\n",
    "# Create the local directories\n",
    "os.makedirs(local_real_path, exist_ok=True)\n",
    "os.makedirs(local_fake_path, exist_ok=True)\n",
    "\n",
    "# --- We are now copying *.png files ---\n",
    "print(\"Copying REAL images (approx. 1000 files)...\")\n",
    "!cp -n \"/content/drive/My Drive/DATASET/real_cifake_images\"/*.png \"/content/local_dataset/real_cifake_images/\"\n",
    "\n",
    "print(\"Copying FAKE images (approx. 1000 files)...\")\n",
    "!cp -n \"/content/drive/My Drive/DATASET/fake_cifake_images\"/*.png \"/content/local_dataset/fake_cifake_images/\"\n",
    "# --- END OF FIX ---\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n--- Copy complete in {end_time - start_time:.2f} seconds! ---\")\n",
    "print(\"All images are now on the fast local disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxTGuyz-eQi8"
   },
   "source": [
    "CELL 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPCMDW6jeBMz",
    "outputId": "5a8e70d8-abd2-4093-c417-8034ddfcbbcc"
   },
   "outputs": [],
   "source": [
    "# [THIS IS THE NEW, CORRECTED CELL 7]\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import cv2  # OpenCV for loading images\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timm\n",
    "from tqdm import tqdm # A nice progress bar\n",
    "\n",
    "# --- 1. Basic Setup ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define our label mapping\n",
    "label_map = {\"real\": 0, \"fake\": 1}\n",
    "\n",
    "# --- 2. Load and Split the Data ---\n",
    "csv_path = \"/content/training_master.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# We must update the paths to point to the new local copy from Cell 6\n",
    "print(\"Updating image paths to point to the new local copy...\")\n",
    "drive_base_path = \"/content/drive/My Drive/DATASET\"\n",
    "local_base_path = \"/content/local_dataset\"\n",
    "df['image_path'] = df['image_path'].str.replace(drive_base_path, local_base_path)\n",
    "print(\"Paths updated. Here is a sample of the new path:\")\n",
    "print(df.iloc[0]['image_path'])\n",
    "# --- END---\n",
    "\n",
    "# Map string labels to numbers\n",
    "df['label_id'] = df['label'].map(label_map)\n",
    "\n",
    "# Split the data (80% train, 20% validation)\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,  # 20% for validation\n",
    "    random_state=42, # For reproducible results\n",
    "    stratify=df['label_id']\n",
    ")\n",
    "\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"Training images: {len(train_df)}\")\n",
    "print(f\"Validation images: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc3ns-RPeSXJ"
   },
   "source": [
    "CELL 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5Acdd7ceBKU",
    "outputId": "e3cadf25-dc20-41a5-883b-164b8ea37269"
   },
   "outputs": [],
   "source": [
    "# [THIS IS THE NEW MODIFIED CELL 8 - EXPERIMENT 4]\n",
    "\n",
    "# ImageNet stats are standard for pre-trained models\n",
    "IMG_SIZE = 224\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# --- CHANGE 1: AGGRESSIVE AUGMENTATIONS ---\n",
    "# We are making the training images much harder to \"memorize\"\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    # TrivialAugment is a very strong, modern augmentation policy\n",
    "    transforms.TrivialAugmentWide(interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    # RandomErasing cuts out a random patch, forcing the model\n",
    "    # to learn from all parts of the image, not just one clue.\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0),\n",
    "])\n",
    "# ----------------------------------------\n",
    "\n",
    "# Simpler transforms for the validation set (NO CHANGE HERE)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# --- 4. Create the Custom Dataset Class (NO CHANGE HERE) ---\n",
    "class DeepfakeCloneDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.image_paths = df['image_path'].values\n",
    "        self.labels = df['label_id'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "        try:\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise IOError(f\"Could not read image: {img_path}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            image = torch.zeros((3, IMG_SIZE, IMG_SIZE), dtype=torch.uint8)\n",
    "            label = 0\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "print(\"Dataset class and NEW AGGRESSIVE transforms defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8DYp9zoeT44"
   },
   "source": [
    "CELL 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyMRJHrmeBHG",
    "outputId": "635f9f76-9b38-4753-d7cf-631572a1667a"
   },
   "outputs": [],
   "source": [
    "# [THIS IS THE NEW MODIFIED CELL 9 - FOR V7]\n",
    "\n",
    "# --- CHANGE 1: BATCH_SIZE must be smaller for this huge model ---\n",
    "BATCH_SIZE = 8\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = DeepfakeCloneDataset(train_df, transform=train_transform)\n",
    "val_dataset = DeepfakeCloneDataset(val_df, transform=val_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    # --- CHANGE 2: num_workers=0 to save RAM ---\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    # --- CHANGE 2: num_workers=0 to save RAM ---\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"DataLoaders created with NEW batch size {BATCH_SIZE} and 0 workers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCi6dJoneXFs"
   },
   "source": [
    "CELL 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTrfORsNeVld",
    "outputId": "13bc12f6-9484-4cb4-92c6-8d4e3d6e0f6d"
   },
   "outputs": [],
   "source": [
    "# [THIS IS THE NEW MODIFIED CELL 10 - EXPERIMENT 5]\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import timm\n",
    "\n",
    "# --- 1. Load the NEW Model ---\n",
    "# --- CHANGE 1: We are upgrading to ConvNeXt-Base ---\n",
    "model = timm.create_model(\n",
    "    'convnext_base',\n",
    "    pretrained=True,\n",
    "    num_classes=2\n",
    ")\n",
    "# --------------------------------------------------\n",
    "model.to(device)\n",
    "\n",
    "# --- 2. Define Loss, Optimizer, Scheduler (Same as last experiment) ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=2\n",
    ")\n",
    "\n",
    "# --- CHANGE 2: New path for our v7 model (SAVING TO GOOGLE DRIVE) ---\n",
    "BEST_MODEL_PATH = \"/content/drive/My Drive/best_model_v7.pth\"\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "print(\"V7 Model (ConvNeXt-Base + Aggressive Aug), saving to Drive. Ready to train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOoNbCpueYlw"
   },
   "source": [
    "CELL 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcYpYflNeV2e",
    "outputId": "4ed72a9b-2a38-4122-9a62-124a8a670a67"
   },
   "outputs": [],
   "source": [
    "# --- 3. Define the Training Function ---\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Use tqdm for a progress bar\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        # Move data to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # --- Forward pass ---\n",
    "        # Get model outputs (logits)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # --- Backward pass and optimization ---\n",
    "        optimizer.zero_grad() # Clear old gradients\n",
    "        loss.backward()       # Calculate new gradients\n",
    "        optimizer.step()      # Update model weights\n",
    "\n",
    "        # --- Statistics ---\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # Get predictions (the class with the highest score)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = total_loss / total_samples\n",
    "    epoch_accuracy = (total_correct / total_samples) * 100\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "# --- 4. Define the Validation Function ---\n",
    "def validate_one_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, etc.)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # We don't need to calculate gradients during validation\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validating\"):\n",
    "            # Move data to GPU\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # --- Forward pass ---\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # --- Statistics ---\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = total_loss / total_samples\n",
    "    epoch_accuracy = (total_correct / total_samples) * 100\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "print(\"Training and Validation helper functions are defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EK7SOo1XeZ4a"
   },
   "source": [
    "CELL 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "UZVeCj5LeVzb",
    "outputId": "ab0f8d88-2441-4af2-d252-5e8b7eeb72d9"
   },
   "outputs": [],
   "source": [
    "# [THIS IS THE NEW MODIFIED CELL 12 - EXPERIMENT 4]\n",
    "\n",
    "# --- CHANGE 1: Train for 30 epochs ---\n",
    "# The task is harder, so we need to train for longer.\n",
    "NUM_EPOCHS = 30\n",
    "# ------------------------------------\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n--- Epoch {epoch + 1} / {NUM_EPOCHS} ---\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    val_loss, val_acc = validate_one_epoch(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Valid Loss: {val_loss:.4f} | Valid Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f\"  *** New best model saved to Drive! Accuracy: {val_acc:.2f}% ***\")\n",
    "\n",
    "print(\"\\n--- Training Complete ---\")\n",
    "print(f\"Best validation accuracy achieved: {best_val_accuracy:.2f}%\")\n",
    "print(f\"Best model saved to: {BEST_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Wlvb8AMebdG"
   },
   "source": [
    "CELL 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7rB3NX1beVtM",
    "outputId": "8c4900d6-ebf4-4b11-be60-fedf5f31864d"
   },
   "outputs": [],
   "source": [
    "# [THIS IS YOUR CELL 13]\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(\"Starting to copy TEST dataset from Drive to local Colab disk...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Define source and destination paths\n",
    "drive_test_path = \"/content/drive/My Drive/DATASET/test\"\n",
    "local_test_path = \"/content/local_dataset/test\"\n",
    "\n",
    "# Create the local directory\n",
    "os.makedirs(local_test_path, exist_ok=True)\n",
    "\n",
    "# Copy all .png files\n",
    "print(\"Copying TEST images...\")\n",
    "!cp -n \"/content/drive/My Drive/DATASET/test/\"*.png \"/content/local_dataset/test/\"\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n--- Test set copy complete in {end_time - start_time:.2f} seconds! ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQh6P3yzec-T"
   },
   "source": [
    "CELL 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JlAYy15eVqs",
    "outputId": "5dd33bc0-5fb3-4fca-edf4-b0e09d7b8795"
   },
   "outputs": [],
   "source": [
    "# [THIS IS THE FINAL CORRECTED CELL 14]\n",
    "\n",
    "import glob\n",
    "import timm\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- 1. Define the correct model path ---\n",
    "BEST_MODEL_PATH = \"/content/drive/My Drive/best_model_v7.pth\" # Correct V7 path\n",
    "\n",
    "# --- 2. Load the Best Model (94.25% score) ---\n",
    "# First, re-create the 'convnext_base' structure\n",
    "model = timm.create_model('convnext_base', pretrained=False, num_classes=2)\n",
    "model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(f\"Best model (94.25%) loaded from '{BEST_MODEL_PATH}'.\")\n",
    "\n",
    "# --- 3. Find All Test Images ---\n",
    "local_test_image_paths = sorted(\n",
    "    glob.glob(\"/content/local_dataset/test/*.png\"),\n",
    "    key=lambda x: int(os.path.basename(x).split('.')[0])\n",
    ")\n",
    "test_df = pd.DataFrame({'image_path': local_test_image_paths, 'label_id': 0})\n",
    "\n",
    "# --- 4. Create Test DataFrame and DataLoader (FIXED) ---\n",
    "test_dataset = DeepfakeCloneDataset(test_df, transform=val_transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    # --- FIX: Use BATCH_SIZE=8 ---\n",
    "    batch_size=BATCH_SIZE, # BATCH_SIZE is 8\n",
    "    shuffle=False,\n",
    "    # --- FIX: Use num_workers=0 ---\n",
    "    num_workers=0\n",
    ")\n",
    "print(\"Test DataLoader is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9oDfv0Oef1m"
   },
   "source": [
    "CELL 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NA5hkVDbefWc",
    "outputId": "03d34de8-db3a-4a9d-d35c-00e4542dcc57"
   },
   "outputs": [],
   "source": [
    "# [THIS IS THE NEW MODIFIED CELL 15 - FOR V7]\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "inv_label_map = {0: \"real\", 1: \"fake\"}\n",
    "all_predictions = []\n",
    "\n",
    "# --- 1. Get All Predictions from the Model ---\n",
    "with torch.no_grad():\n",
    "    for images, _ in tqdm(test_loader, desc=\"Predicting on test set\"):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted_ids = torch.max(outputs.data, 1)\n",
    "        all_predictions.extend(predicted_ids.cpu().numpy())\n",
    "print(f\"Generated {len(all_predictions)} predictions.\")\n",
    "\n",
    "# --- 2. Format the Predictions into the JSON ---\n",
    "final_json_output = []\n",
    "for i, pred_id in enumerate(all_predictions):\n",
    "    image_filename = os.path.basename(test_df.iloc[i]['image_path'])\n",
    "    image_index = int(image_filename.split('.')[0])\n",
    "    label_str = inv_label_map[pred_id]\n",
    "\n",
    "    final_json_output.append({\n",
    "        \"index\": image_index,\n",
    "        \"prediction\": \"fake\" if label_str == \"fake\" else \"real\"\n",
    "    })\n",
    "\n",
    "# --- 3. Save the JSON File (MODIFIED) ---\n",
    "submission_file_path = \"/content/drive/My Drive/Catalyst_prediction_v7.json\"\n",
    "\n",
    "with open(submission_file_path, 'w') as f:\n",
    "    json.dump(final_json_output, f, indent=4)\n",
    "\n",
    "print(f\"\\n--- SUCCESS! ---\")\n",
    "print(f\"V7 Submission file saved to your Google Drive: {submission_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
